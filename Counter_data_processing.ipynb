{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs are saved. Run the next block\n"
     ]
    }
   ],
   "source": [
    "#Enter the following details to start the analysis.\n",
    "\n",
    "#************************************************\n",
    "# Enter the working directory in the following format \n",
    "#(Copy paste the address path to the directory with double slash inbetween)\n",
    "# path = \"C:\\\\Users\\Dhivyabharathi\\\\OneDrive - Trinity College Dublin\\mywork\\\\Python scripts\\\\Dashboard\"\n",
    "path = \"C:\\\\Users\\\\ctrans\\\\OneDrive - iitr.ac.in\\\\Dhivya_Research\\\\Python_Scripts\"\n",
    "#***********************************************\n",
    "\n",
    "#Enter the dates\n",
    "#Date range should not be more than seven days\n",
    "start_date='2019-12-01'\n",
    "End_date='2019-12-02'\n",
    "#***********************************************\n",
    "\n",
    "#Enter the counter Id\n",
    "location=1506 \n",
    "#***********************************************\n",
    "\n",
    "#Enter the direction of traffic as South bound or North boun or West bound or East bound\n",
    "direction='South bound' \n",
    "#***********************************************\n",
    "\n",
    "#Enter the speedlimit \n",
    "vf=120 #kmph\n",
    "#***********************************************\n",
    "\n",
    "#Saving variables to directory\n",
    "import os\n",
    "os.chdir(path)\n",
    "import pickle\n",
    "with open('dash_variables','wb') as f:\n",
    "    pickle.dump([path, location, start_date, End_date, direction, vf],f)\n",
    "    \n",
    "print('Inputs are saved. Run the next block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5d294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctrans\\AppData\\Local\\Temp\\ipykernel_18876\\3273844419.py:15: DtypeWarning: Columns (12,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(url(temp1[i]))\n",
      "C:\\Users\\ctrans\\AppData\\Local\\Temp\\ipykernel_18876\\3273844419.py:15: DtypeWarning: Columns (12,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(url(temp1[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "#Function to create the url for downloading data set\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def url(t):\n",
    "    format2=t.strftime(\"%Y-%m-%d\")\n",
    "    format1=t.strftime(\"%Y/%m/%d\")\n",
    "    filename='https://data.tii.ie/Datasets/TrafficCountData/'+ format1 + '/per-vehicle-records-' + format2 +'.csv'\n",
    "    return filename\n",
    "\n",
    "#download selected days data and write to csv\n",
    "def download(start_date, End_date):\n",
    "    temp1=pd.date_range(start_date,End_date, freq='D') \n",
    "    for i in range(0,temp1.size):\n",
    "        data = pd.read_csv(url(temp1[i]))\n",
    "        tempname=temp1[i].strftime(\"%Y-%m-%d\")+ '.csv'\n",
    "        data.to_csv(tempname) \n",
    "        \n",
    "# clearing temporary variables\n",
    "def clear(variables):\n",
    "    for var in variables:\n",
    "        del var\n",
    "        \n",
    "#removing unwanted columns and formatting datetime       \n",
    "def process(data):\n",
    "    data['Datetime']=data.year.astype(str)+ '-' +data.month.astype(str)+'-'+data.day.astype(str)+ ' ' + data.hour.astype(str)+ ':' + data.minute.astype(str) + ':' + data.second.astype(str)\n",
    "    data['Datetime']=pd.to_datetime(data['Datetime'].astype(str), format='%Y-%m-%d %H:%M:%S')\n",
    "    data1 = data[['Datetime', 'cosit' ,'classname', 'lanename', 'speed', 'headway']].copy()\n",
    "#     data1['lanename'] = data1['lanename'].str.replace('\\d+', '')\n",
    "    data1.set_index('Datetime', inplace=True)\n",
    "    return data1\n",
    "\n",
    "#splitting directions of traffic\n",
    "def direction(data3):\n",
    "    if 'Southbound 2' in data3['lanename'].unique():\n",
    "        searchfor_s=['Southbound ' + str(i + 1) for i in range(0,4)]\n",
    "    elif 'Southbound' in data3['lanename'].unique():\n",
    "        searchfor_s = ['Southbound']\n",
    "    elif 'Westbound' in data3['lanename'].unique():\n",
    "        searchfor_s = ['Westbound']\n",
    "    elif 'Westbound 2' in data3['lanename'].unique():\n",
    "        searchfor_s=['Westbound ' + str(i + 1) for i in range(0,4)]\n",
    "    else:\n",
    "        searchfor_s=[]\n",
    "    return searchfor_s\n",
    "\n",
    "#Dowload the counter data \n",
    "os.chdir(r'.\\Processedfiles')\n",
    "download(start_date, End_date)\n",
    "filelist=os.listdir(path)\n",
    "print('Download completed')\n",
    "# filelist\n",
    "\n",
    "# #Vehicle composition Estimation\n",
    "# veh_composition=result.groupby('classname')['lanename'].count().reset_index()\n",
    "# veh_composition['Percentage'] = 100 * veh_composition['lanename']  / veh_composition['lanename'].sum()\n",
    "# veh_composition.set_index('classname', inplace=True)\n",
    "\n",
    "# os.chdir(path)\n",
    "# import pickle\n",
    "# filename = 'veh_composition'\n",
    "# outfile = open(filename,'wb')\n",
    "# pickle.dump(veh_composition,outfile)\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd91363-ff38-4d94-b089-2bd6616a84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing block 1\n",
    "print('Data is getting prepared')\n",
    "dfseries=[]\n",
    "result=pd.DataFrame()\n",
    "data=pd.DataFrame()\n",
    "for file in filelist:\n",
    "    data =pd.read_csv(file) #reading a csv\n",
    "    data2=process(data) #removing unwanted columns and formatting datetime\n",
    "    data3=data2[(data2['cosit']==location)]\n",
    "    searchfor=direction(data3)\n",
    "    data4=data3[data3['lanename'].str.contains('|'.join(searchfor))]\n",
    "    dfseries.append(data4)\n",
    "    clear(['data', 'data2', 'data3', 'data4'])\n",
    "    result= pd.concat(dfseries)\n",
    "    clear(['dfseries'])\n",
    "print('Data preparation completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing block 2\n",
    "#Estimation of aggregated flow and speed\n",
    "data=result\n",
    "flow=[]\n",
    "speed=[]\n",
    "flow.append(data['classname'].resample('H').count()) #Flow is aggregated hourly\n",
    "speed.append(data['speed'].resample('H').mean()) #Speed is aggregated hourly\n",
    "merged_flow = pd.concat(flow)\n",
    "merged_speed = pd.concat(speed)\n",
    "\n",
    "#database preparation\n",
    "merged=pd.concat([merged_flow, merged_speed], axis=1)\n",
    "merged.columns =['HourlyFlow','meanspeed']\n",
    "\n",
    "os.chdir(r'.\\Processedfiles')\n",
    "merged.to_csv('Output.csv')\n",
    "print('Data Processing completed')\n",
    "print('Results are saved into the Processedfiles directory')\n",
    "merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
